\documentclass[12pt,a4paper,openright,twoside]{book}
\usepackage[utf8]{inputenc}
\usepackage{disi-thesis}
\usepackage{code-lstlistings}
\usepackage{notes}
\usepackage{shortcuts}
\usepackage{acronym}

\school{\unibo}
\programme{Corso di Laurea in Ingegneria e Scienze Informatiche}
\title{Un sistema di realtà aumentata per la Robotica di sciame}
\author{Marchetti Davide}
\date{\today}
\subject{Programmazione ad oggetti}
\supervisor{Mirko Viroli}
\cosupervisor{Gianluca Aguzzi}
\session{IV}
\academicyear{2024-2025}

% Definition of acronyms
\acrodef{IoT}{Internet of Thing}
\acrodef{vm}[VM]{Virtual Machine}

\acrodef{js}[JS]{Java Script}
\acrodef{AR}[AR]{Realtà Aumentata}
\acrodef{VR}[VR]{Realtà Virtuale}

\acrodef{mqtt}[MQTT]{Message Queuing Telemetry Transport}

\acrodef{wcs}[WCS]{Sistema di Coordinate del Mondo}

\mainlinespacing{1.241} % line spacing in mainmatter, comment to default (1)

\begin{document}

\frontmatter\frontispiece

\begin{abstract}	
Max 2000 characters, strict.
\ac{js}
\end{abstract}

\begin{dedication} % this is optional
Optional. Max a few lines.
\end{dedication}

%----------------------------------------------------------------------------------------
\tableofcontents   
\listoffigures     % (optional) comment if empty
\lstlistoflistings % (optional) comment if empty
%----------------------------------------------------------------------------------------

\mainmatter

%----------------------------------------------------------------------------------------
\chapter{Introduzione}\label{chap:introduzione}
%----------------------------------------------------------------------------------------

Write your intro here.
\sidenote{Add sidenotes in this way. They are named after the author of the thesis}

You can use acronyms that your defined previously,
such as \ac{IoT}.
%
If you use acronyms twice,
they will be written in full only once
(indeed, you can mention the \ac{IoT} now without it being fully explained).
%
In some cases, you may need a plural form of the acronym.
%
For instance,
that you are discussing \acp{vm},
you may need both \ac{vm} and \acp{vm}.

\paragraph{Struttura della tesi}

\note{At the end, describe the structure of the paper}

\chapter{Background}\label{chap:background} % (fold)

\section{Project Emerge}\label{sec:project_emerge} % (fold)

% section Project Emerge (end)

\section{Realtà aumentata}\label{sec:realta_aumentata} % (fold)

% section Realtà aumentata (end)

\section{ThreeJS}\label{sec:threejs} % (fold)
ThreeJS è una libreria in JavaScript progettata per semplificare lo sviluppo di applicazioni di grafica tridimensionale in ambienti web. Si basa su WebGL, un’API a basso livello che consente l’accesso diretto alle funzionalità della GPU attraverso il browser.
L’utilizzo diretto di WebGL richiede una conoscenza approfondita della pipeline grafica e della programmazione tramite shader, per questo motivo ThreeJS introduce un livello di astrazione che consente di sviluppare scene tridimensionali complesse riducendo la complessità implementativa, pur mantenendo un elevato grado di flessibilità.
\\
%
L’architettura di ThreeJS riflette i principali concetti della grafica computazionale tridimensionale e si basa su tre componenti fondamentali: scena, telecamera e \rd.
\\
Una scena contiene tutti gli oggetti tridimensionali, le sorgenti luminose e gli elementi di supporto. La telecamera definisce il punto di vista dell’osservatore e può essere di tipo prospettico o ortografico, influenzando il modello di proiezione della scena sul piano di visualizzazione.
\\
Il \rd, generalmente \texttt{WebGLRenderer}, si occupa di eseguire la pipeline di \rding{} sfruttando le funzionalità offerte da WebGL.
%
Gli oggetti rappresentati in una scena, chiamati \textit{mesh}, sono costituiti da due componenti principali:
\begin{itemize}
    \item \textbf{Geometria}: descrive la struttura dei vertici, delle normali e delle coordinate texture
    \item \textbf{Materiale}: definisce le proprietà visive dell’oggetto, texture e il suo comportamento rispetto alle sorgenti luminose
\end{itemize}
% \\
% Le geometrie , mentre i materiali . ThreeJS mette a disposizione diversi modelli di shading, includendo sia approcci tradizionali sia modelli basati sul Physically Based Rendering (PBR).
%
\lstinputlisting[language=JavaScript,caption={Esempio di una scena 3D con ThreeJS},label={lst:sample-threejs}]{listings/Threejs.js}
%
Un aspetto di particolare interesse di ThreeJS è il supporto nativo allo standard WebXR, un’API che consente la realizzazione di applicazioni di \acl{VR} e \acl{AR} direttamente all’interno del browser. ThreeJS fornisce un livello di integrazione che semplifica la gestione dei dispositivi XR, come visori VR e dispositivi mobili compatibili con AR, astrando la complessità della comunicazione diretta con l’API WebXR.
%
Attraverso l’utilizzo di componenti dedicati, è possibile creare ambienti immersivi tridimensionali in cui la scena viene renderizzata in modo stereoscopico e aggiornata in funzione dei movimenti dell’utente. L’integrazione con WebXR permette inoltre di gestire input avanzati, come controller e sistemi di tracciamento.
%
% section ThreeJS (end)
%
\section{MQTT}\label{sec:sec_mqtt} % (fold)
%
Il \acf{mqtt} è un protocollo di comunicazione, divenuto standard OASIS \cite{std-mqtt-5}, basato sul paradigma \textit{publish-subscribe} con l'ausilio di un protocollo di trasporto bidirezionale e affidabile.
Progettato per facilitare la comunicazione all'interno di reti instabili o tra dispositivi che utilizzano un numero limitato di risorse.
In questo modello sono necessari tre componenti principali, come mostrato in \Cref{fig:back-mqtt-comm}:
\begin{itemize}
    \item \textbf{broker}: nodo centrale con il compito di distribuire i messaggi
    \item \textbf{publisher}: dispositivo o applicazione che pubblica messaggi
    \item \textbf{subscriber}: dispositivo o applicazione che riceve messaggi
\end{itemize}
%
\begin{figure}[htp]
    \centering
    \includegraphics[width=1\linewidth]{./figures/back-mqtt.png}
    \caption{Esempio di comunicazione con \acs{mqtt}}
    \label{fig:back-mqtt-comm}
\end{figure}
%
Più nello specifico, ogni messaggio inviato e ricevuto viene organizzato in stringhe gerarchiche, chiamate \textit{topic}. Ogni publisher pubblica un messagio in un topic e un subscriber riceve i messaggi dai topic a cui viene sottoscritto.
L'operazione di filtraggio dei messaggi nei relativi topic viene svolta dal \textit{broker}.
\\
L'architettura di \acs{mqtt} introduce diversi disaccoppiamenti tra mittenti e destinatari:
\begin{itemize}
    \item \textbf{Disaccoppiamento spaziale}: ogni publisher non ha la necessità di conoscere ogni subscriber (e viceversa), ognuno di essi comunica esclusivamente con il \textit{broker}
    \item \textbf{Disaccoppiamento temporale}: un publisher e un subscriber non hanno la necessità di essere attivi simultaneamente per poter comunicare
    \item \textbf{Disaccoppiamento di sincronizzazione}: le operazioni di invio e ricezione di messaggi non sono processi che interrompono il flusso di esecuzione 
\end{itemize}
%
Tipicamente \acs{mqtt} instaura un canale di comunicazione bidirezionale sfruttando il protocollo \textit{TCP/IP}, il quale garantisce affidabilità e robustezza del canale, ma soprattutto l'ordine dei messaggi inviati rimane invariato in ricezione.
%
% section MQTT (end)

% chapter Background (end)

\chapter{Analisi}\label{chap:analisi} % (fold)

\section{Obiettivi}\label{sec:obiettivi} % (fold)
%
Questa tesi si pone come obiettivo la realizzazione di un'applicazione web che permetta di trasformare il sistema emulato, utilizzato nella notte dei ricercatori, in una scena in realtà aumentata sfruttando un dispositivo dotato di una fotocamera.
L'applicativo deve inizialmente calibrare un'arena virtuale, sfruttando la telecamera del dispositivo e quattro marker ArUco posizionati nel mondo reale.
Una volta individuati e calcolata una stima della loro posizione all'interno di una scena 3D, devono essere disegnati i robot emulati dal sistema, all'interno dell'arena virtuale. Le informazioni relative alla posizione ed orientamento di ogni elemento vengono condivise mediante un broker \ac{mqtt} in un \textit{topic} specifico.
%
% section Obiettivi (end)

\section{Requisiti}\label{sec:requisiti} % (fold)
%
\begin{itemize}
    \item Ricerca dei marker ArUco presenti nell'inquadratura della telecamera fisica
    \item Creazione di un arena virtuale in una scena 3D, sovrapposta ai marker posizionati nel mondo reale
    \begin{itemize}
        \item Calibrazione di un nuovo sistema di coordinate
        \item Posizionamento di una \textit{mesh} sul piano dell'arena
    \end{itemize}
    \item Rappresentazione dei robot emulati nella scena in realtà aumentata ricevendo tutte le informazioni dal broker \ac{mqtt}
\end{itemize}
%
% section Requisiti (end)

\section{Modello}\label{sec:modello} % (fold)

\subsection{WebXR e HTTPS}\label{sub:webxr_e_https} % (fold)
WebXR rappresenta un’evoluzione significativa nel web, consentendo l’accesso diretto ad esperienze di realtà virtuale e aumentata attraverso il browser. Tuttavia, questa tecnologia comporta dei rischi elevati se la sicurezza dell'utente non viene gestita correttamente.
\\
La WebXR Device API permette di interagire con numerevoli componenti e sensori avanzati come accelerometri, giroscopi, fotocamere e microfoni, e persino dispositivi di input specializzati.
Alcune funzionalità, come l’uso di \texttt{immersive-ar} o \texttt{immersive-vr}, non possono essere attivate se la connessione non è HTTPS o se la pagina non è in un contesto \textit{trusted}, proprio per evitare che contenuti malevoli possano compromettere la privacy o la sicurezza del dispositivo.
\\
Per prevenire che le informazioni sensibili vengano intercettate o manipolate, tutte le sessioni WebXR devono essere servite tramite connessioni sicure HTTPS. Si basa su TLS (Transport Layer Security), e garantisce la codifica \textit{end-to-end} dei dati tra client e server, autenticità del sito web e integrità dei contenuti, impedendo attacchi di tipo \textit{man-in-the-middle} o \textit{spoofing}.
\\
Il browser non permette l’inizializzazione di sessioni immersive su pagine non sicure e interrompe l'esecuzione di operazioni non approvate dall’utente. Quest'ultime riprendono la normale esecuzione nel momento in cui l'utente acconsente all’accesso agli eventuali sensori e dati sensibili condivisi.
% subsection WebXR e HTTPS (end)

\subsection{Broker MQTT}\label{sub:broker_mqtt} % (fold)
La comunicazione con il sistema emulato è un'aspetto fondamentale per lo sviluppo di questo progetto. Il broker \ac{mqtt} costituisce il nodo centrale della comunicazione, consentendo lo scambio in tempo reale di dati, comandi e stati tra i diversi componenti.
Tale architettura garantisce la sincronizzazione fra i due sistemi senza richiedere connessioni dirette tra ogni modulo, semplificando la gestione del sistema e favorendo l’integrazione di ulteriori componenti.
Analogamente a quanto avviene nelle esperienze \textit{WebXR}, servite tramite \textit{HTTPS}, è essenziale che la comunicazione con il broker avvenga attraverso un canale sicuro, come ad esempio \textit{TLS/SSL}, al fine di proteggere le informazioni da intercettazioni o manomissioni e garantire l’integrità dei dati scambiati.
\\
Grazie ad \ac{mqtt}, la soluzione proposta è facilmente integrabile al sistema reale con i dispositivi fisici. Nel progetto \textit{Project-Emerge} il sistema interagisce con il broker come publisher, inviando i dati relativi alle posizioni dei robot nel tempo, mentre in questo progetto la comunicazione si concentra nella ricezione e nell'elaborazione dei dati ricevuti.
%
% subsection Broker MQTT (end)

\subsection{Arena simulata}\label{sub:arena_simulata} % (fold)
L'arena simulata riproduce il comportamento dei robot all'interno del mondo reale, comunicando con il sistema principale mediante un broker \ac{mqtt}. Questa simulazione pubblica tutte le informazioni relative alle posizioni ed orientamento all'interno di un \textit{topic}.
\\
La soluzione implementata si sottoscrive ai relativi \textit{topic} e al momento della ricezione di un messaggio, elabora i dati al suo interno per poi renderizzare le varie mesh all'interno della scena 3D.
Uno dei problemi principali analizzati riguarda la differenza di sistema di coordinate di entrambe le arene: l'arena simulata non corrisponde all'arena virtuale nella scena, quindi una posizione nel sistema simulato, se utilizzata all'interno della scena senza alcuna manipolazione, comporta a posizionamenti errati all'interno della scena.
Il posizionamento dei robot deve essere effettuato all'interno di un'area precisamente delimitata nella scena, nasce la necessità di adattare le posizioni relative ricevute nel sistema di coordinate corrente.
Oltre a questa trasformazione, si aggrega la trasformazione dalle coordinate relative all'arena al \acl{wcs}.
% subsection Arena simulata (end)

% section Modello (end)

% chapter Analisi (end)

\chapter{Progettazione}\label{chap:progettazione} % (fold)
%
\section{ThreeJS e WebXR}\label{sec:threejs_e_webxr} % (fold)
%
La realizzazione di una scena in realtà aumentata con l'ausilio di ThreeJS è molto immediato, in quanto la libreria integra la maggior parte delle funzionalità di  WebXR.
Le due librerie coesistono elaborando i dati in contemporanea: ThreeJS si occupa di renderizzare tutti gli elementi della scena e l'immagine della fotocamera ad ogni frame, mentre WebXR gestisce il dispositivo XR utilizzato ed eventuali controller.
\\
Tuttavia, WebXR categorizza l'immagine delle telacamera, ed altre informazioni non rilevanti in questa tesi, come contenuto sensibile. Perciò per poter avviare una qualsiasi sessione in realtà aumentata (o virtuale), è necessario che l'utente dia il consenso all'utilizzo della telecamera.
%
Inoltre per ottenere l'immagine stessa durante una sessione XR, utilizzando il modulo aggiuntivo \textit{WebXR Raw Camera Access Module} \cite{webxr_raw_camera}.
Grazie a questo modulo si ha la possibilità di ottenere una texture, nel contesto di WebGL, rappresentante l'immagine della fotocamera in uno specifico \texttt{XRFrame}, durante l'esecuzione di una \texttt{XRSession}.
%
% section ThreeJS e WebXR (end)
%
\section{Marker Detection e Pose Estimation}\label{sec:marker_detection_e_pose_estimation} % (fold)
%
Per ricercare all'interno di un'immagine i marker ArUco viene utilizzata la libreria \textit{js-aruco} \cite{js_aruco2}.
Questa l'libreria analizza i dati di un immagine e attraverso algoritmi e tecniche di Visione Artificiale, trova la posizione dei marker ArUco di un dizionario specifico, all'interno dell'immagine data.
Inoltre offre delle tecniche per stimare la posizione dei marker in uno spazio tridimensionale.
\\
Nel flusso esecutivo il riconoscimento, essendo una parte molto onerosa, non viene eseguito ad ogni iterazione del \textit{loop} principale, ma viene eseguita soltanto dopo un determinato numero di \textit{frame} dall'ultima esecuzione se l'arena non è stata gia calibrata.
Ciò garantisce la fluidità dell'applicativo in fase di calibrazione, ma porta a non avere un tracking immediato dei marker presenti.
\begin{figure}[htp]
    \centering
    \includegraphics[width=.4\linewidth]{./figures/diag-marker.png}
    \caption{Diagramma delle classi della classe \texttt{Marker}}
    \label{fig:diag-marker}
\end{figure}
Viene utilizzata una classe di supporto, chiamata \texttt{Marker}, per tenere traccia di tutti i marker trovati e le loro informazioni relative alla \texttt{pose}. La \texttt{pose} è un oggetto, generato dalla libreria \textit{posit2} integrata con \textit{js-aruco2}, contenente i seguenti parametri:
\begin{itemize}
    \item \textbf{error}: un valore relativo all'errore stimato del risultato
    \item \textbf{translation}: un vettore di traslazione 3D
    \item \textbf{rotation}: una matrice di rotazione, di dimensione $3 \times 3$
\end{itemize}
\texttt{Posit}, quando utilizzata, genera due possibili \texttt{pose}: una chiamata \texttt{bestPose}, avente il valore dell'errore inferiore, ed una saconda chiamata \texttt{alternativePose}, avente un errore maggiore.
La classe \texttt{Marker} è stata predisposta per fornire entrambe le possibili \texttt{pose}; tuttavia nella soluzione implementata verrà utilizzata soltanto quella migliore.
%
% section Marker Detection e Pose Estimation (end)
%
\section{Arena virtuale}\label{sec:arena_virtuale} % (fold)
%
L'arena è un'area, delimitata dai marker ArUco posizionati nel mondo reale, con lo scopo di disegnare all'interno tutti i robot emulati dal simulatore esterno.
Per creare e calibrare un'arena virturale, è necessario definire quali sono i limiti dell'arena stessa. Questi limiti sono i \texttt{Corner}, la cui posizione nella scena virtuale viene definita dai marker ArUco ricercati nella fase precedente.
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.3\linewidth]{./figures/diag-corner.png}
    \caption{Diagramma delle classi di \texttt{Corner}}
    \label{fig:diag-corner}
\end{figure}
Ogni \texttt{Corner} necessita dei seguenti parametri:
\begin{itemize}
    \item \texttt{position}: la posizione nella scena 3D
    \item \texttt{rotation}: la rotazione nella scena 3D, influenzata dalla proiezione prospettica della fotocamera
    \item \texttt{location}: indica quale angolo dell'arena rappresenta nel mondo reale (per esempio l'angolo in alto a destra, oppure in basso a sinistra)
\end{itemize}
Un'arena per essere consistente, deve presentare quattro \texttt{Corner} ognuno dei quali rappresenta una \texttt{Location} specifica.
Le \texttt{Location} sono indispensabili per il calcolo degli assi relativi dell'arena stessa. Questi ultimi vengono utilizzati per posizionare i robot all'interno a partire dall'origine dell'arena.
%
\subsection{Calibrazione dell'arena}\label{sub:calibrazione_dell_arena} % (fold)
Una volta aver ottenuto un'arena valida, bisogna effettuare delle opportune operazioni per poter permettere il posizionamento di robot all'interno dell'area delimitata.
In particolare, il simulatore invia le posizioni dei robot relative all'origine dell'ambiente simulato $(0, 0, 0)$, tuttavia la posizione dell'origine dell'arena raramente corrisponde a quella del sistema emulato. Perciò le posizioni ricevute, relative all'origine della scena emulata, devono essere trasformate in posizioni relative al nuovo sistema di coordinate.
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.4\linewidth]{./figures/diag-arena-origin.png}
    \caption{Diagramma delle classi parziale: \texttt{Arena} e l'origine}
    \label{fig:diag-arena-origin}
\end{figure}
%
Viene considerato il punto centrale del poligono definito dai quattro angoli dell'arena, come origine del nuovo sistema di coordinate.
In matematica, quest'utlimo è chiamato centroide (centro geometrico o centro della figura): si ottiene calcolando la media aritmetica della posizioni dei punti di una figura piana o solida.
$$
C = \frac{1}{n}\sum_{i = 0}^{n}{x_i}
$$
%
Il punto trovato corrisponde all'origine dell'arena nel sistema di coordinate del mondo della scena 3D.
%
\subsubsection{Calcolo degli assi di riferimento}\label{sec:calcolo_degli_assi_di_riferimento} % (fold)
Per permettere la traslazione dei robot nel nuovo sistema di riferimento, bisogna definire un'asse orizzontale ed uno verticale, entrambi relativi all'arena.
Qui entra in gioco la \texttt{Location} di ogni \texttt{Corner}: data la posizione di due \texttt{Corner}, il vettore normalizzato della differenza fra le posizioni definisce un asse dell'arena.
Per l'asse verticale si prendono in considerazione due angoli che si trovano entrambi a destra o a sinistra (ad esempio \texttt{TOP\_LEFT} e \texttt{BOT\_LEFT}). Il vettore risultante avrà il verso che punta all'angolo superiore.
Mentre per l'asse orizzontale si prendono in considerazione due corner che si trovano, idealmente, sulla parte inferiore oppure sulla parte superiore (ad esempio \texttt{TOP\_LEFT} e \texttt{TOP\_RIGHT}).
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.3\linewidth]{./figures/diag-arena-axes.png}
    \caption{Diagramma delle classi parziale: \texttt{Arena} e \texttt{ArenaAxes}}
    \label{fig:diag-arena-axes}
\end{figure}
%
% subsubsection Calcolo degli assi di riferimento (end)
%
% subsection Calibrazione dell'arena (end)
%
\subsection{Comunicazione con il broker MQTT}\label{sub:comunicazione_con_il_broker_mqtt} % (fold)
%
La comunicazione con un broker \ac{mqtt} deve avvenire utilizzando una connessione sicura, in quanto il contesto dell'applicativo è sviluppato con il protocollo \textit{HTTPS}.
Soltanto in un ambiente sicuro, il \textit{browser} potrà permettere la comunicazione con quest'ultimo.
Per implementare il client \ac{mqtt} viene utilizzata la libreria \textit{mqtt.js} \cite{mqttjs}, che permette di configurare e gestire una connessione ad un broker \ac{mqtt}.
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.4\linewidth]{./figures/diag-mqtt-client.png}
    \caption{Diagramma delle classi del \texttt{MQTTClient}}
    \label{fig:diag-mqtt-client}
\end{figure}
Viene implementata la classe \texttt{MQTTClient}, che permette di connettersi ad un broker, sottoscriversi ai topic, ed eseguire delle operazioni specifiche quando un messaggio viene ricevuto.
%
\subsubsection{Gestione dei Robot emulati}\label{sec:gestione_dei_robot_emulati} % (fold)
Le informazioni ricevute dal broker, in formato \textit{JSON}, vengono memorizzate all'interno della classe \texttt{Robot}. Quest'ultima racchiude le seguenti informazioni:
\begin{itemize}
    \item \textbf{id}: l'id del robot emulato
    \item \textbf{mesh}: la mesh utilizzata per il \textit{render} e le relative informazioni sulla posizione globale
    \item \textbf{orientation}: angolo di rotazione, in radianti, rispetto all'asse $y$ dell'arena
\end{itemize}
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.4\linewidth]{./figures/diag-robot.png}
    \caption{Diagramma delle classi del \texttt{Robot}}
    \label{fig:diag-robot}
\end{figure}

Tutti i robot utilizzano lo stesso modello di base, per questo motivo il modello stesso viene caricato una volta sola e, ogni volta che viene aggiunto un robot, viene creata una nuova copia con un nuovo identificativo nella scena di \textit{ThreeJS}.
Per ogni robot non è necessario tenere traccia delle posizioni relative all'emulatore: infatti ogni posizione viene convertita nel nuovo sistema di coordinate prima di creare un'istanza di questa classe.
% subsubsection Gestione dei Robot emulati (end)
%
% subsection Comunicazione con il broker MQTT (end)
%
\subsection{Posizionamento e orientamento dei robot}\label{sub:posizionamento_e_orientamento_dei_robot} % (fold)
Il posizionamento dell'arena virtuale non è sempre lo stesso, perciò non è possibile definire un posizionamento statico dei \texttt{Robot}.
A causa del posizionamento dinamico si ha la necessità di allineare arbitrariamente la \textit{mesh}. In particolare la base della mesh, contenente le ruote dei robot, deve essere posizionata sul piano virtuale dell'arena.
Geometricamente il vettore normale della base deve avere stessa direzione ma verso opposto rispetto al vettore normale del piano dell'arena.
In questa soluzione viene proposto un orientamento sfruttando le matrici di trasformazione della \textit{mesh} e quella dell'arena: data la matrice di trasformazione iniziale $M_i$, si può dire che moltiplicando questa matrice per una matrice di rotazione $R$, si ottiene la matrice di trasformazione finale $M_f$.
\[
    M_f = M_i \cdot R
\]
In questo caso la matrice $M_i$ rappresenta la matrice di trasformazione della \textit{mesh}, mentre la matrice $M_f$ rappresenta quella dell'arena. Trovando la matrice $R$ è possibile applicare le opportune trasformazioni per orientare corretamente una \textit{mesh} sul piano dell'arena.
\[
    R = M_f / M_i = M_f \cdot M_i^{-1}
\]
La matrice dell'arena viene ricavata utilizzando gli assi calcolati dopo la calibrazione, invece la matrice dei \texttt{Robot} viene definita in maniera statica. Analizzando la \textit{mesh} del robot, si determinano i vettori delle normali nello spazio di coordinate del mondo. In particolare bisogna definire il vettore normale della base, della parte frontale e del lato destro della \textit{mesh} (destro perchè viene utilizzato un sistema di coordinate che segue le regole della mano destra).
\\
Per quanto riguarda l'orientamento dei robot, viene utilizzato l'asse $y$ dell'arena come asse di rotazione, in modo da rispettare quello del simulatore. La rotazione, ogni volta che deve essere aggiornata, viene sommata o sottratta a quella corrente.

% subsection Posizionamento e orientamento dei robot (end)

\subsection{Movimento dei robot}\label{sub:movimento_dei_robot} % (fold)
Per poter muovere i robot all'interno dell'arena, bisogna calcolare la loro posizione all'interno della scena. Le posizioni ricevute dal broker \ac{mqtt} vengono normalizzate, per cambiare sistema di riferimento nel sistema di coordinate relativo all'arena virtuale. Tuttavia queste coordinate normalizzate sono ancora relative ad un origne diversa da quella della scena, dunque non è possible utilizzarle nel \ac{wcs}.
La classe \texttt{Arena} implementa un metodo che converte le coordinate relative date in coordinate del mondo, permettendo una corretta traslazione delle \textit{mesh}.
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.4\linewidth]{./figures/diag-robot-movement.png}
    \caption{Diagramma delle classi parziale: \texttt{Arena} e movimento dei \texttt{Robot}}
    \label{fig:diag-robot-movement}
\end{figure}
Questo metodo sfrutterà sia l'origine che gli assi dell'arena: l'origine definisce il punto in cui tutte le traslazione devono iniziare, mentre gli assi indicano le direzioni su cui devono essere effettuate. Non è sufficiente sommare le coordinate di una posizione relativa alle coordinate dell'origine, in quanto tutte le traslazioni avvengo nel \ac{wcs}: supponendo di effettuare una traslazione lungo l'asse $x$ del mondo, non si ha alcuna certezza che corrisponda a quella corretta nel piano dell'arena.
In questo caso gli assi del mondo e dell'arena non corrispondono; utilizzando direttamente gli assi dell'arena il problema non si presenta in alcuna situazione.
% subsection Movimento dei robot (end)

% section Arena virtuale (end)

% chapter Progettazione (end)

\chapter{Implementazione}\label{chap:implementazione} % (fold)
Il flusso di esecuzione dell'applicazione è il seguente:
\begin{enumerate}
    \item Inizializzazione della scena 3D e del supporto con WebXR, stabilisce una connessione con il broker \acs{mqtt} ed inizializza il detector per i marker ArUco con l'opportuno dizionario
    \item Nel momento in cui l'utente inizia la sessione in realtà aumentata, attraverso l'apposito pulsante, viene definito il loop di esecuzione con le seguenti fasi:
    \begin{itemize}
        \item \texttt{update}, esegue la ricerca dei marker ed eventualmente inizializza un'arena virtuale
        \item \texttt{render}, disegna l'intera scena sullo schermo
    \end{itemize}
\end{enumerate}
%
\section{ThreeJS e WebXR}\label{sec:impl_threejs_e_webxr} % (fold)
\subsection{Integrazione di una telecamera}\label{sub:impl_integrazione_di_una_telecamera} % (fold)
Per integrare la telecamera del dispositivo all'interno di una scena ThreeJS, è necessario aver inizializzato il \rd, successivamente bisogna abilitare il componente \texttt{xr} all'interno del \rd{} stesso.
%
\lstinputlisting[language=JavaScript,caption={Inizializzazione della scena 3D con il supporto per WebXR},label={lst:init-scene-camera}]{./listings/ar-session.js}
Per poter ottenere l'immagine della fotocamera, è necessario specificare la feature \texttt{camera-access}, fornita dal modulo \textit{WebXR Raw Camera Access Module} \cite{webxr_raw_camera}.
%
% subsection Integrazione di una telecamera (end)

% section ThreeJS e WebXR (end)

\section{Marker Detection e Pose Estimation}\label{sec:impl_marker_detection_e_pose_estimation} % (fold)

\subsection{Ricerca dei marker}\label{sub:impl_ricerca_dei_marker} % (fold)
La libreria utilizzata, \textit{js-aruco2} \cite{js_aruco2}, fornisce i metodi necessari per effettuare la ricerca di marker ArUco appartenenti ad un dizionario specifico, partendo da un'immagine (solitamente ottenuta da un \texttt{canvas}).
%
\lstinputlisting[language=JavaScript,caption={Inizializzazione della scena 3D con il supporto per WebXR},label={lst:init-scene-camera}]{./listings/get-camera-image.js}
%
In questo caso non è possibile ottenere l'immagine della fotocamera in maniera diretta \cite{webxr_raw_camera}.
Grazie alla feature \texttt{camera-access}, è possibile ottenere una texture, contenente l'immagine della fotocamera, in un formato non elaborabile lato CPU (\texttt{WebGLTexture}).
Tuttavia è possibile utilizzare questo specifico formato come sfondo di una scena. Per questo motivo, viene utilizzata una scena ausiliaria con lo scopo di renderizzare la texture ottenuta, per poi effettuare uno snapshot dello stato attuale della scena. Così facendo è possibile realizzare un immagine elaborabile da \textit{js-aruco2}.
Prima di utilizzarla bisogna capovolgere l'immagine: il metodo \texttt{readRenderTargetPixels} richiama il metodo di \textit{OpenGL} chiamato \texttt{glReadPixels}. Quest'ultimo inizia a leggere i pixel dall'angolo in basso a sinistra dell'immagine, mentre l'origine della finestra è posta all'angolo in alto a sinistra. Questa differenza nelle origini porta ad avere un'immagine capovolta verticalmente.
Il metodo \texttt{flipImageVertically} analizza metà dell'immagine, partendo dall'alto, e ad ogni iterazione scambia la riga corrente con la rispettiva riga dal fondo.
\lstinputlisting[language=JavaScript,caption={Inizializzazione della scena 3D con il supporto per WebXR},label={lst:init-scene-camera}]{./listings/scene-snapshot.js}
%
Una volta ottenuta un'immagine.
La ricerca dei marker viene eseguita dopo un numero di \texttt{frame} del \rd.
\lstinputlisting[language=JavaScript,caption={Inizializzazione della scena 3D con il supporto per WebXR},label={lst:init-scene-camera}]{./listings/find-markers.js}
% subsection Ricerca dei marker (end)

\subsection{Stima delle posizioni}\label{sub:impl_stima_delle_posizioni} % (fold)
La stima delle posizioni viene calcolata sfruttando la libreria \textit{posit2}, fornita da \textit{js-aruco2}.
La quale all'interno calibra una telecamera virtuale, conoscendo la larghezza dell'elemento \textit{HTML} dove viene renderizzata la scena e la grandezza dei marker ArUco reali, per poter trasformare le coordinate nello spazio dello schermo in coordinate della scena.
Per poter ottenere dei risultati attendibili, è necessario centrare le coordinate 2D dei \textit{corner} trovati nella sezione \cref{sub:impl_ricerca_dei_marker}, all'interno del \textit{canvas}.
%
\lstinputlisting[language=JavaScript,caption={Stima delle posizioni dei marker in uno spazio 3D},label={lst:estimate-marker-pos}]{./listings/estimate-position.js}
Vengono tracciati tutti i marker, con \texttt{Id} unico, che successivamente, dopo le opportune manipolazioni, verranno utilizzati per la creazione dell'arena virtuale.
%
% subsection Stima delle posizioni (end)

% section Marker Detection e Pose Estimation (end)

\section{Arena Virtuale}\label{sec:impl_arena_virtuale} % (fold)
%
\subsection{Calibrazione dell'arena}\label{sub:impl_calibrazione_dell_arena} % (fold)
L'inizializzazione dell'arena avviene nel momento in cui sono stati tracciati esattamente quattro marker differenti. A questo punto si procede con il calcolo dell'origine e degli asssi di traslazione dell'arena.
\subsubsection{Calcolo dell'origine}\label{sec:calcolo_dell_origine} % (fold)
Per calcolare il centroide di una figura ad $n$ dimensioni, bisogna calcolare la media di ogni coordinata per ogni suo punto. In questo caso si hanno $3$ dimensioni, quindi si calcola la media delle coordinate $x$, la media delle coordinate $y$ e la media delle coordinate $z$ di ogni punto. Le medie ottenute rappresentano le coordinate tridimensionali del centroide della figura.
%
\lstinputlisting[language=JavaScript,caption={Calcolo del centroide di una serie di punti},label={lst:evaulate-arena-center}]{./listings/calc-centroid.js}
%
% subsubsection Calcolo dell'origine (end)
%
\subsubsection{Definizione degli assi}\label{sec:definizione_degli_assi} % (fold)
Conoscendo gli \texttt{Id} dei marker tracciati, ognuno dei quali corrisponde ad un angolo della scena specifico (\texttt{Location}), è possibile ottenere gli assi di traslazione dell'arena creata.
%
\lstinputlisting[language=JavaScript,caption={Calcolo degli assi di traslazione dell'arena},label={lst:evaulate-arena-axes}]{./listings/calc-axes.js}
%
Si prendono due angoli, che nella realtà si troverebbero sullo stesso lato, e si calcola il vettore distanza fra loro:
\[
    dist = p_2 - p_1
\]
Il risultato ottenuto viene poi normalizzato, così da ottenere valori compresi nell'intervallo $\left[-1, 1\right]$ per facilitare le operazioni di traslazione e rotazione.
Inoltre viene anche calcolato un terzo asse, calcolando il prodotto vettoriale tra i due assi calcolati in precedenza.
\[
    z = x \times y
\]
Quest'ultimo asse può essere considerato come il vettore normale della superficie dell'arena; in seguito verrà utilizzato per orientare correttamente la \textit{mesh} dei robot sulla superficie stessa.
%
% subsubsection Definizione degli assi (end)
%
% subsection Calibrazione dell'arena (end)

\subsection{Comunicazione con il broker}\label{sub:impl_comunicazione_con_il_broker} % (fold)
Nel momento in cui l'arena viene creata, viene definito il comportamento di un \texttt{MQTTClient} alla ricezione di ogni messaggio.
\lstinputlisting[language=JavaScript,caption={Creazione del client MQTT ed iscrizione ai topic},label={lst:broker-connect}]{./listings/broker-connect.js}
In questo caso l'unico topic rilevante è quello delle posizioni dei robot (\texttt{robots/\{robotId\}/position}), perciò non è necessario filtrare i messaggi per topic (essendo iscritto soltanto ad uno).
Ogni volta che viene ricevuto un messaggio, viene normalizzata la posizione ricevuta nelle coordinate dell'arena virtuale: come specificato in precedenza, l'arena simulata e l'arena virutale non solo hanno due sistemi di coordinate differenti, ma la dimensione delle due arene è differente.
Per questo motivo tutte le posizioni ricevute dal simulatore, vengono normalizzate con la seguente formula:
$$
    normPos = \left( \frac{x \cdot xSize}{simulatedSize}, \frac{y \cdot ySize}{simulatedSize}, z\right)
$$
Dove $xSize$ e $ySize$ rappresentano rispettivamente la metà della lunghezza di due lati consecutivi dell'arena, mentre $simulatedSize$ è la dimensione del mondo dell'arena simulata.
%
\lstinputlisting[language=JavaScript,caption={Operazioni eseguite alla ricezione di ogni messaggio},label={lst:broker-message}]{./listings/broker-message.js}
%
% subsection Comunicazione con il broker (end)

\subsection{Posizionamento e orientamento}\label{sub:posizionamento_e_orientamento} % (fold)
A questo punto viene calcolata la matrice di trasformazione per poter allineare la \textit{mesh} con il piano dell'arena. Si calcolano le matrici di trasformazione sia iniziale, della \textit{mesh}, che finale, corrispondente al piano dell'arena.
Nel sistema di coordinate della \textit{mesh}, il vettore normale del robot corrisponde all'asse delle $y$ avente verso opposto, per questo motivo, nella matrice di trasformazione finale, \texttt{tb}, vengono scambiati l'asse $z$ e l'asse $y$. Infatti la base della \textit{mesh} deve posizionarsi nella stessa direzione della normale dell'arena (asse $z$). Inoltre lo stesso asse $z$ viene negato per permettere alla base di posizionarsi correttamente.
Calcolate le due matrici, si effettua un prodotto tra quella finale (di arrivo), e l'inversa di quella iniziale, così da ottenere la matrice di rotazione da applicare alla \textit{mesh}.
\lstinputlisting[language=JavaScript,caption={Posizionamento della mesh sull'arena virtuale},label={lst:pose-robot}]{./listings/pose-robot.js}
%
Per quanto riguarda l'orientamento dei \textit{Robot}, bisogna tenere traccia dell'orientamento precedente per poter calcolare un \textit{offset}, da utilizzare per effettuare la rotazione locale della \textit{mesh}.
Nel caso in cui si ruotasse la \textit{mesh} reimpostando la rotazione, si perderebbe il posizionamento sull'arena, in quanto la matrice di rotazione calcolata precedentemente verrebbe sovrascritta da una nuova.
Per questo motivo, dopo aver calcolato la differenza fra l'orientamento precedente e quello attuale, si utilizza il metodo \texttt{rotateOnAxis}, che permette di calcolare una rotazione rispetto ad un asse sommandola alla rotazione corrente di un \texttt{Object3D}. Infine si aggiorna l'orientamento attuale del \texttt{Robot} con il nuovo valore.
\lstinputlisting[language=JavaScript,caption={Rotazione del robot all'interno dell'arena},label={lst:orient-robot}]{./listings/orient-robot.js}
% subsection Posizionamento e orientamento (end)

\subsection{Movimento dei robot}\label{sub:impl_movimento_dei_robot} % (fold)
Prima di effettuare una qualsiasi trasformazione si ricalcolano gli assi e l'origine dell'arena, se necessario: ciò accade quando vengono modificate le coordinate nel mondo di uno dei quattro \texttt{Corner} dell'arena.
La posizione di ogni robot viene calcolata partendo dall'origine dell'arena, a cui viene sommato il vettore corrispondente alla traslazione sull'asse $x$ e $y$.
\lstinputlisting[language=JavaScript,caption={Traslazione dei robot all'interno dell'arena},label={lst:move-robot}]{./listings/move-robot.js}
% subsection Movimento dei robot (end)

% section Arena Virtuale (end)

% chapter Implementazione (end)

\chapter{Valutazione}\label{chap:valutazione} % (fold)

% chapter Valutazione (end)

\chapter{Conclusioni e lavori futuri}\label{chap:conclusioni_e_lavori_futuri} % (fold)

% chapter Conclusioni e lavori futuri (end)

%----------------------------------------------------------------------------------------
% BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\backmatter

\nocite{*} % Remove this as soon as you have the first citation

\bibliographystyle{alpha}
\bibliography{bibliography}

\begin{acknowledgements} % this is optional
Optional. Max 1 page.
\end{acknowledgements}

\end{document}

